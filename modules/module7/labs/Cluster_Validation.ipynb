{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Validation\n",
    "\n",
    "One of the big issues with clustering methods is that they will return clusters even if the data does not contain any clusters. Thus its important to assess clustering tendency before the analysis and also validate the quality of the results after clustering.\n",
    "\n",
    "In general clustering validation statistics can be grouped into following 4 classes. \n",
    "\n",
    "Relative clustering validation: This evaluates the clustering structure by varying different parameter values for the same algorithm (e.g.,: varying the number of clusters k). It’s generally used for determining the optimal number of clusters.\n",
    "\n",
    "External clustering validation: This method compares the results of a cluster analysis to an externally known result, such as externally provided class labels. Since we know the “true” cluster number in advance, this approach is mainly used for selecting the right clustering algorithm for a specific dataset.\n",
    "\n",
    "Internal clustering validation: This method uses internal information of the clustering process to evaluate the goodness of a clustering structure without reference to external information. It can be also used for estimating the number of clusters and the appropriate clustering algorithm without any external data.\n",
    "\n",
    "Clustering stability validation: This method is a special version of internal validation. It evaluates the consistency of a clustering result by comparing it with the clusters obtained after each column is removed, one at a time.\n",
    "\n",
    "We will be using following lis of packages for clusters evaluation\n",
    "\n",
    "* **cluster: ** For analyzing cluster silhouettes\n",
    "* **factoextra: ** For visualizing clusters using ggplot2 plotting system\n",
    "* **NbClust: ** For determining the optimal number of clusters in the data\n",
    "* **fpc: ** For computing clustering validation statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(factoextra)\n",
    "library(cluster)\n",
    "library(fpc)\n",
    "library(NbClust)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Load the Dow Jones Index dataset from /directory/dowjines/dow_jones_index.data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customers_data = read.csv(\"../../../datasets/wholesale/Wholesale_customers_data.csv\",sep=',',header=TRUE)\n",
    "head(customers_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine the optimal number of clusters\n",
    "\n",
    "The NbClust package will compute the optimal number of clusters for your data with a single function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "customers_scaled = customers_data[,names(customers_data)!=('Region')]\n",
    "table(customers_data$Region)\n",
    "# attach(iris)\n",
    "# iris_scaled = iris[,-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute the number of clusters\n",
    "library(NbClust)\n",
    "nb <- NbClust(customers_scaled, distance = \"euclidean\", min.nc = 2,\n",
    "        max.nc = 10, method = \"complete\", index =\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So NBclust is suggesting to form 2 clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "library(factoextra)\n",
    "fviz_nbclust(nb) + theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use eclust() function in factoextra package. eclust() stands for enhanced clustering. It simplifies the workflow of clustering analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "km.res <- eclust(customers_scaled, \"kmeans\", k = 2,nstart = 25, graph = FALSE)\n",
    "# k-means group number of each observation\n",
    "table(km.res$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize k-means clusters\n",
    "fviz_cluster(km.res, geom = \"point\", frame.type = \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the kmeans clustering with K=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# K-means clustering\n",
    "km.res1 <- eclust(customers_scaled, \"kmeans\", k = 3,nstart = 25, graph = FALSE)\n",
    "# k-means group number of each observation\n",
    "table(km.res1$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize k-means clusters\n",
    "fviz_cluster(km.res1, geom = \"point\", frame.type = \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical Clustering Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Enhanced hierarchical clustering\n",
    "res.hc <- eclust(customers_scaled, \"hclust\", k = 3, method = \"complete\", graph = FALSE) \n",
    "table(res.hc$cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dendrogram\n",
    "fviz_dend(res.hc, rect = TRUE, show_labels = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Internal clustering validation measures\n",
    "\n",
    "The goal of clustering algorithms is to split the dataset into clusters of objects, such that:\n",
    "\n",
    "* the objects in the same cluster are similar as much as possible,\n",
    "* the objects in different clusters are highly distinct\n",
    "\n",
    "i'e we want the average distance within cluster to be as small as possible; and the average distance between clusters to be as large as possible.\n",
    "\n",
    "Following measures help us evaluate the clusters internally.\n",
    "\n",
    "**Compactness: ** measures evaluate how close are the objects within the same cluster. A lower within-cluster variation is an indicator of a good compactness (i.e., a good clustering). The different indices for evaluating the compactness of clusters are base on distance measures such as the cluster-wise within average/median distances between observations.\n",
    "\n",
    "**Separation: ** measures determine how well-separated a cluster is from other clusters. The indices used as separation measures include: distances between cluster centers the pairwise minimum distances between objects in different clusters\n",
    "\n",
    "**Connectivity: ** corresponds to what extent items are placed in the same cluster as their nearest neighbors in the data space. The connectivity has a value between 0 and infinity and should be minimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Silhouette analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Silhouette analysis measures how well an observation is clustered and it estimates the average distance between clusters. The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters. The silhouette coefficient of observations can be computed using the function silhouette() in cluster package. \n",
    "\n",
    "$$silhouette(x, dist, ...)$$ where\n",
    "\n",
    "\n",
    "\n",
    "_x_: an integer vector containing the cluster assignment of observations\n",
    "\n",
    "_dist_: a dissimilarity object created by the function dist()\n",
    "\n",
    "The function silhouette() returns an object, of class silhouette containing:\n",
    "\n",
    "* The cluster number of each observation **i**\n",
    "* The neighbor cluster of **i** (the cluster, not containing **i**, for which the average dissimilarity between its observations and **i** is minimal)\n",
    "* The silhouette width $s_i$ of each observation\n",
    "\n",
    "\n",
    "The R code below computes silhouette analysis and a plot is generated using R base plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Silhouette coefficient of observations\n",
    "library(\"cluster\")\n",
    "sil <- silhouette(km.res1$cluster, dist(customers_scaled))\n",
    "head(sil[, 1:3], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Silhouette plot\n",
    "plot(sil, main =\"Silhouette plot - K-means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(factoextra)\n",
    "fviz_silhouette(sil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of the silhouette analysis can be computed using the function summary.silhouette() as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Summary of silhouette analysis\n",
    "si.sum <- summary(sil)\n",
    "# Average silhouette width of each cluster\n",
    "si.sum$clus.avg.widths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The total average (mean of all individual silhouette widths)\n",
    "si.sum$avg.width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The size of each clusters\n",
    "si.sum$clus.sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Samples with a negative silhouette coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Silhouette widths of each observation\n",
    "table(sil[, 1:3]<0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few samples that have a negative silhouette coefficient in kmeans clustering. This means that they are not in the right cluster.\n",
    "\n",
    "We can find the name of these samples and determine the clusters they are closer (neighbor cluster), as follow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Objects with negative silhouette\n",
    "neg_sil_index <- which(sil[, 'sil_width'] < 0)\n",
    "sil[neg_sil_index, , drop = FALSE]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dunn index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dunn index is another internal clustering validation measure which can be computed as follows,\n",
    "\n",
    "* For each cluster, compute the distance between each of the objects in the cluster and the objects in the other clusters\n",
    "* Use the minimum of this pairwise distance as the inter-cluster separation (min.separation)\n",
    "* For each cluster, compute the distance between the objects in the same cluster.\n",
    "* Use the maximal intra-cluster distance (i.e maximum diameter) as the intra-cluster compactness\n",
    "* Calculate Dunn index (D) as follow:\n",
    "\n",
    "$$D=\\frac{min.separation}{max.diameter}$$\n",
    "\n",
    "The function cluster.stats() in fpc package and the NbClust() in NbClust package are used to compute Dunn index and many other indices. It returns a list containing many components useful for analyzing the intrinsic characteristics of a clustering:\n",
    "\n",
    "* cluster.number: number of clusters\n",
    "* cluster.size: vector containing the number of points in each cluster\n",
    "* average.distance, median.distance: vector containing the cluster-wise within average/median distances\n",
    "* average.between: average distance between clusters. We want it to be as large as possible\n",
    "* average.within: average distance within clusters. We want it to be as small as possible\n",
    "* clus.avg.silwidths: vector of cluster average silhouette widths. Recall that, the silhouette width is also an estimate of the * average distance between clusters. Its value is comprised between 1 and -1 with a value of 1 indicating a very good cluster.\n",
    "* within.cluster.ss: a generalization of the within clusters sum of squares (k-means objective function), which is obtained if d is a Euclidean distance matrix.\n",
    "* dunn, dunn2: Dunn index\n",
    "* corrected.rand, vi: Two indexes to assess the similarity of two clustering: the corrected Rand index and Meila’s VI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(fpc)\n",
    "# Compute pairwise-distance matrices\n",
    "dd <- dist(customers_scaled, method =\"euclidean\")\n",
    "# Statistics for k-means clustering\n",
    "km_stats <- cluster.stats(dd, km.res1$cluster)\n",
    "# (k-means) within clusters sum of squares\n",
    "km_stats$within.cluster.ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (k-means) cluster average silhouette widths\n",
    "km_stats$clus.avg.silwidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display all statistics\n",
    "km_stats"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
