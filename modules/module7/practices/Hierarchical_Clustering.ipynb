{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "In this practice, we will apply hierarchical clustering to the same data sets as we did in [k-means clustering practice](KMeans_Clustering.ipynb). Take a look at that practice first, if you haven't done so yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data from the file\n",
    "data1 <- read.csv(\"../../../datasets/toydata/data1.csv\",header=TRUE)\n",
    "\n",
    "str(data1)\n",
    "# Visualize the data\n",
    "library(ggplot2)\n",
    "pl1 <- ggplot(data1, aes(X, Y)) + geom_point(colour=\"black\")\n",
    "pl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Let's apply hierarchical clustering to this data set\n",
    "set.seed(42)\n",
    "hc_clust11 <- hclust(dist(data1[, 1:2]), method=\"complete\")\n",
    "plot(hc_clust11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a dendrogram, the height gives a good idea about how \"far\" the clusters are in terms of dissimilarity. Above, it seems like there are two clusters in this data set based on the heights of the tree branches. Let's cut it at two clusters and visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cut the tree at two clusters; it returns labels for each point.\n",
    "cut2 = cutree(hc_clust11, 2)\n",
    "# use labels to visualize hclust clusters\n",
    "pl1 <- ggplot(data1, aes(X, Y)) + geom_point(aes(colour=factor(cut2))) + theme(legend.position=\"top\")\n",
    "pl1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same by using *eclust* function of **factoextra** library like following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(factoextra)\n",
    "# run k-means on this data and visualize \n",
    "km <- eclust(data1[, 1:2], \"kmeans\", k=2, nstart=20, graph=FALSE)\n",
    "fviz_cluster(km, geom=\"point\", frame=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run hclust on this data and visualize \n",
    "hc <- eclust(data1[, 1:2], \"hclust\", k=2, method=\"complete\", graph=FALSE) \n",
    "# plot clusters\n",
    "fviz_cluster(hc, geom=\"point\", frame=FALSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# also plot the dendrogram\n",
    "fviz_dend(hc, rect = TRUE, show_labels = FALSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's compare the cluster assignments to the actual class labels\n",
    "table(cut2, data1$class)\n",
    "# or \n",
    "table(hc$cluster, data1$class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it looks like for three clusters. **Now it's your turn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run hclust on this data and visualize \n",
    "hc2 <- eclust(<what goes in here>) \n",
    "# plot clusters\n",
    "fviz_cluster(hc2, <what goes in here>)\n",
    "# Dendrogram\n",
    "fviz_dend(hc2, <what goes in here>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three clusters don't make much sense as can be seen from the branch heights. Here, we can use **NbClust** just as in the \n",
    "[k-means clustering practice](KMeans_Clustering.ipynb) to find out at what level we should cut the tree. \n",
    "\n",
    "Let's apply it to the second data set. **Now it's your turn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read data from the file \n",
    "data2 <- read.csv(\"../../../datasets/toydata/data2.csv\",header=TRUE)\n",
    "\n",
    "# Visualize the data\n",
    "pl2 <- ggplot(data2, aes(X, Y)) + geom_point(colour=\"black\")\n",
    "pl2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with two clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run hclust on this data and visualize \n",
    "hc3 <- <what goes in here>\n",
    "# plot clusters\n",
    "fviz_cluster(<what goes in here>)\n",
    "# Dendrogram\n",
    "fviz_dend(<what goes in here>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  see how well it does; compute the confusion given the actual labels. **Now it's your turn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table(<what goes in here>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the same approach for the third data set. From [k-means clustering practice](KMeans_Clustering.ipynb), \n",
    "we know that best number of clusters is either 3 or 6 depending on our choice of scale. Let's see how hclust does for those numbers. **Now it's your turn:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read data from file\n",
    "data3 <- read.csv(\"../../../datasets/toydata/data3.csv\",header=TRUE)\n",
    "pl3 <- ggplot(data3, aes(X, Y)) + geom_point(colour=\"black\")\n",
    "pl3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, try for 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run hclust on this data and visualize \n",
    "hc4 <- <what goes in here>\n",
    "# plot clusters\n",
    "fviz_cluster(<what goes in here>)\n",
    "# Dendrogram\n",
    "fviz_dend(<what goes in here>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try for 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# run hclust on this data and visualize \n",
    "hc5 <- <what goes in here>\n",
    "# plot clusters\n",
    "fviz_cluster(<what goes in here>)\n",
    "# Dendrogram\n",
    "fviz_dend(<what goes in here>) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Judging from the branch heights, both 3 and 6 look like reasonable numbers for number of clusters. 4 is not bad either. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
