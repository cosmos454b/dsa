{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 7 - Clustering Exercises\n",
    "\n",
    "This notebook tests the concepts of clustering using seeds dataset. The data belongs to three different varieties of wheat: Kama, Rosa and Canadian, with 70 elements for each variety. The data is ideal for doing classification and clustering. \n",
    "\n",
    "Perform clustering on the dataset using K-Means, Hierarchical and Dbscan methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seeds_data = read.csv(\"../../../datasets/seeds/seeds_data\",header=FALSE,sep=\"\")\n",
    "head(seeds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "header = c(\"area\",\"perimeter\",\"compactness\",\"length_of_kernel\",\"width_of_kernel\",\"asymmetry_coefficient\",\"length_of_kernel_groove\",\"variety\")\n",
    "names(seeds_data)=header\n",
    "summary(seeds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We should normalize the data so that variables that are on a larger scale doesn't influence the distance calculation\n",
    "# by contribute more and dominate the hierarchical clustering\n",
    "\n",
    "# Normalize the data first. You can normalize the variables in a data frame by using the preProcess function \n",
    "# in the \"caret\" package.\n",
    "\n",
    "library(caret)\n",
    "# Create a normalized data frame called \"seeds_data_norm\" by running the following commands:\n",
    "\n",
    "preproc = preProcess(seeds_data)\n",
    "seeds_data_norm = predict(preproc, seeds_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "summary(seeds_data_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values are normalised. All columns have 0 mean and standard deviation of 1 now. All columns contribute equally when calculating distances between each other. You can verify running below cell. Dont get confused looking at the first few decimal values of mean value 2.85. Look at the end where it is raised to the power of -16. So the value is **0.000000000000000285104126567158** which is almost zero. The standard deviation is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean(seeds_data_norm$area)\n",
    "sd(seeds_data_norm$area)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 1: ** Compute the distances between data points (using euclidean distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 1 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2: **  Run the Hierarchical clustering algorithm (using method=\"complete\") on the normalized data \"seeds_data_norm\". Plot the cluster using plot() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 2 goes here\n",
    "\n",
    "# Run Hierarchical clustering algorithm (using method=\"complete\") on the normalized data seeds_data_norm\n",
    "seeds_Hcluster = \n",
    "\n",
    "#plot the dendrogram of the hierarchical clustering process\n",
    "plot(seeds_Hcluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 3: ** Divide the data points into 3 clusters by using the cutree function. Assign this clusters to variable named seeds_HclusterGroups. Which cluster has maximum number of points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 3 goes here\n",
    "\n",
    "# Use curtree function to divide the data points into 3 clusters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 4: ** Use a 2-way table to see how many observations are classified into correct cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 4 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 5: ** Use tapply to compare the average values in each of the variables for the 3 clusters (the centroids of the clusters).  Check the average values for the unnormalized data so that it is easier to interpret. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 5 goes here\n",
    "\n",
    "# An example:  t(tapply(seeds_data$perimeter,seeds_HclusterGroups,mean))\n",
    "\n",
    "# seeds_HclusterGroups are the cluster assignments for the 210 observations in the dataset. So in above command \n",
    "# seeds_HclusterGroups will group the data in seeds_data$perimeter according to three clusters and mean is applied to each group.\n",
    "# You will get the mean perimeter of each cluster in this way\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 6: ** Assign the points to three different clusters cluster1, cluster2 and cluster3 using subset function on seeds_data. subset the data based on cluster assignments 1,2 and 3 in seeds_HclusterGroups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code for activity 6 goes here\n",
    "\n",
    "# Assign points to clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head(cluster1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 7: ** Plot the clusters using ggplot on seeds_data dataset. Plot length_of_kernel on x-axis and width_of_kernel on y-axis. Use seeds_HclusterGroups for color parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 7 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 8: **  Run the Hierarchical clustering algorithm using eclust function and also using complete linkage on the normalized data \"seeds_data_norm\". Plot the clusters using fviz_cluster function in factoExtra package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 8 goes here\n",
    "\n",
    "\n",
    "# plot clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 9: **  Run the Kmeans clustering algorithm on the normalized data \"seeds_data_norm\" and store the result in the variable seeds_Kmeans. Use 3 as the number of clusters and nstart=30. Extract the cluster assignments into a variable called seeds_kmeansClusters. Plot the clusters using fviz_cluster function in factoExtra package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 9 goes here\n",
    "\n",
    "# Run the k-means clustering algorithm on the normalized data creating 3 clusters. \n",
    "\n",
    "# seeds_Kmeans = kmeans()\n",
    "\n",
    "\n",
    "# Extract clusters into seeds_kmeansClusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table(seeds_kmeansClusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 10: ** Use a 2-way table to see how many observations are classified into correct clusters. Compare predicted cluster assignments in seeds_kmeansClusters with values in seeds_data$variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 10 goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think of the confusion table? Since this is unsupervised learning, the algorithms wouldn't know the correct class labels. The cluster numbers are arbitrary, but does it seem that Kmeans does a good job in clustering? How do you explain seemingly overlapping clusters in your plot? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DBscan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 11: ** Run DBscan algorithm on the normalized data \"seeds_data_norm\" and store the result in the variable db. Use eps=0.1 amd minPts = 5. Plot the clusters using fviz_cluster function in factoExtra package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 11 goes here\n",
    "\n",
    "# Plot DBSCAN results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DBscan is performing very poorly on the dataset with eps value of 0.1 and MinPts=5. Find the appropriate eps value to use by plotting KNNdistplot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 12: **Find the appropriate eps value to use for seeds_data_norm dataset using KNNdistplot function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 12 goes here\n",
    "\n",
    "library(dbscan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 13: ** Run DBscan algorithm again on \"seeds_data_norm\" using eps that you identified in activity 12 amd minPts = 5. Plot the clusters using fviz_cluster function in factoExtra package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Your code for activity 13 goes here\n",
    "\n",
    "# Plot DBSCAN results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you have seen in the practice notebook DBscan is sensitive to eps value and MinPts arument values and doesn't perform well on all datasets because of varying densities of cluster populations. DBscan is not an ideal choice for this dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
