{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM LAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Support Vector Classifier lab discussed how support vector machines are used to classify data using non linear boundaries.  The dependent variable in IRIS data is scattered every where, making it hard to make a linear boundary for classifying the observations. Fit a SVM model to classify the observations into classes Setosa, Virginica and Versicolor using a polynomial kernal.\n",
    "\n",
    "### Load R Library with Iris Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(\"e1071\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show yourself the top of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "head(iris,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attach the iris data in memory so you can reference it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "attach(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a model using the \"svm\" function using a linear kernal first and evaluate its performance.\n",
    "\n",
    "**Reference: ** \n",
    "\n",
    "   [SVM tutorial 1](http://www.di.fc.ul.pt/~jpn/r/svm/svm.html#non-linearly-separable-data) \n",
    "   \n",
    "   [SVM tutorial 2](https://rpubs.com/ryankelly/svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model using Sepal.Length and Sepal.Width as the predictors. Use a linear kernal to fit the model.\n",
    "svm.model <- svm(Species ~ Sepal.Length + Sepal.Width, data = iris, kernel = \"linear\")\n",
    "\n",
    "# Plot the Species and show the support vectors on graph. \n",
    "# the + signs are support vectors\n",
    "plot(iris$Sepal.Length, iris$Sepal.Width, col = as.integer(iris[, 5]), # color the points based on species \n",
    "     pch = c(\"o\",\"+\")[1:150 %in% svm.model$index + 1], # Mark the support vectors with a `+` sign and test with a `o` sign\n",
    "                                                       # \"1:150 %in% svm.model$index\" will generate a vector of size 150\n",
    "                                                       # with TRUE and FALSE values. A TRUE is assigned if the value is a \n",
    "                                                       # support vector. Addimg one to the vector will give values 1 and 2 \n",
    "                                                       # instead of TRUE(1) and FALSE(0). Every 1 in the vector is displayed\n",
    "                                                       # as o and 2 is displayed as +. \n",
    "     cex = 2, \n",
    "     xlab = \"Sepal length\", ylab = \"Sepal width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the Species by splitting the feature space into three different regions according to species class\n",
    "plot(svm.model, iris, Sepal.Width ~ Sepal.Length, # Plot the model predictions with sepal.width on y-axis and sepal.length\n",
    "                                                  # on x-axis\n",
    "     slice = list(sepal.width = 1, sepal.length = 2)) # a list of named numeric values for the dimensions held constant \n",
    "                                                      # slice is needed if more than two variables are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions of species using the svm model built\n",
    "svm.pred  <- predict(svm.model, iris[,-5]) \n",
    "\n",
    "# Build a confusion matrix for the predictions made against the original classes of flowers\n",
    "library(caret)\n",
    "confusionMatrix(svm.pred, iris[,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The svm model did not do a great job with a linear kernal. The accuracy of the model is 81.3\n",
    "         \n",
    "         (49+38+35)/150  --- number of TRUE predictions/total observations \n",
    "         \n",
    "**Reference: ** [Confusion matrix function and its results](http://rpubs.com/prcuny/161764)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the model using a polynomial kernal and Sepal.Length, Sepal.Width as predictor variables.\n",
    "svm.model <- svm(Species ~ Sepal.Length + Sepal.Width, data = iris, kernel = 'polynomial', degree=8, coef0=1)\n",
    "                      # For polynomial kernels we use the parameter degree to adjust the polynomial order. \n",
    "                      # For radial kernels we use the gamma parameter to adjust the y value.\n",
    "                      # Independent term in kernel function. It is only significant in ‘polynomial’ and ‘sigmoid’ kernals\n",
    "                  \n",
    "plot(svm.model, iris, Sepal.Width ~ Sepal.Length,      # Plot the predictions\n",
    "     slice = list(Sepal.Width = 1, Sepal.Length = 2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.pred  <- predict(svm.model, iris[,-5]) \n",
    "confusionMatrix(svm.pred, iris[,5]) # show the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# There is no improvement in the accuracy of the model even after using a polynomial of degree 8. \n",
    "# We only used just two attributes for making predictions. Use all independent variables for building the model.\n",
    "svm.model <- svm(Species ~ ., data = iris, kernel = 'polynomial', degree=8, coef0=1)\n",
    "plot(svm.model, iris, Sepal.Width ~ Sepal.Length, \n",
    "     slice = list(Petal.Width = 3, Petal.Length = 2.5)) # showing a 2D slice of the 4D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.pred  <- predict(svm.model, iris[,-5]) \n",
    "confusionMatrix(svm.pred, iris[,5]) # show the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There it is. Using all variables as predcitos we got 98% accuracy in our model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
